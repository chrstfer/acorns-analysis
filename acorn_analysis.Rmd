Example analysis of "stats_data.csv" for survey of statistical methods
========================================================

**Author:** [John Stanton-Geddes](www.johnstantongeddes.org), <john.stantongeddes.research@gmail.com>
**Created:** 2013-05-13

Data is a subset of data file from the paper "Walter D. Koenig and Johannes M. H. Knops. 2013. Large-scale spatial synchrony and cross-synchrony in acorn production by two California oaks. Ecology. 94:83â€“93. http://dx.doi.org/10.1890/12-0940.1" downloaded from [Ecological Archives](http://esapubs.org/archive/ecol/E094/009/). Seven of the original 13 environmental variables were selected based on an analysis of the full data set (acorn_analysis.Rmd) to reduce complexity of model fitting for participants. Some of the columns were renamed for convenience of analysis in R.

Response is acorn_count (per 30 seconds of counting, log transformed) collected from multiple sites over multiple years with many potential predictors. 

We in no way intend this as a criticism or an endorsement of the analysis performed by Koenig and Knops. We quite liked their paper, but simply selected this data set as it was freely available from *Ecological Archives* and fit our requirements of a single response and a number of potentially-important and associated predictors.

----------------------------------------------------------

Load and examine data

```{r}
library(MASS)
library(nlme)
library(lme4)
library(MuMIn)
library(ggplot2)

statsdata <- read.csv("stats_data.csv", header=TRUE, sep=",")
head(statsdata)
str(statsdata)
```

Check distribution of acorn.count

```{r acorndist}
hist(statsdata$acorn_count) # Mode at 0 and flat to 3 
```

## Graphical exploration ##
```{r explore}
pairs(statsdata[,4:11])

# Fewer variables
pairs(statsdata[,c(4:8)])
pairs(statsdata[,c(4,9:11)])
```

## Model selection by step-wise deletion ##

Fit mixed-effects model with site and year as random effects and all environmental predictors as fixed. 

```{r lmer}
lmer1 <- lmer(acorn_count ~ mean_max_April_temp + mean_max_March_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + mean_max_summer_temp + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer1)
anova(lmer1)

lmer2 <- lmer(acorn_count ~ mean_max_April_temp + mean_max_March_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer2)
anova(lmer2, lmer1)
# Drop mean_max_summer_temp
anova(lmer2)

lmer3 <- lmer(acorn_count ~ mean_max_April_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer3)
anova(lmer3, lmer2)
# Drop mean_max_March_temp
anova(lmer3)

lmer4 <- lmer(acorn_count ~ mean_max_April_temp + April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer4)
anova(lmer4, lmer3)
# Drop March_rain
anova(lmer4)

lmer5 <- lmer(acorn_count ~ April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer5)
anova(lmer5, lmer4)
# Drop mean_max_April_temp
anova(lmer5)

lmer6 <- lmer(acorn_count ~ March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer6)
anova(lmer6, lmer5)
# Retain April_rain

lmer7 <- lmer(acorn_count ~ April_rain + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer7)
anova(lmer7, lmer5)
# Marginally retain March_rain_lagged1 at alpha=0.05, but not after multiple testing

lmer8 <- lmer(acorn_count ~ April_rain + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer8)
anova(lmer8, lmer5)
# Marginally retain April_rain_lagged1 at alpha=0.05, but not after multiple testing

# Check correlations among these variables
pairs(statsdata[,c(4,8:10)])
```

Final model retains April_rain. March_rain_lagged1 and April_rain_lagged1 are marginally significant at alpha=0.05 but would not be retained if correcting for multiple testing.

## Model selection by AIC ##

Use dredge function in the [MuMIn](http://cran.r-project.org/web/packages/MuMIn/MuMIn.pdf) package that performs automated model selection testing all possible combinations of models. Model averaging of the 'best' models. 


```{r dredge}
best.subsets<-dredge(lmer1,rank="AIC",trace=TRUE,fixed=~n)

print(best.subsets,abbrev.names=FALSE)

#Dredge reports two best fit models. Average them with MuMIn.

(attr(best.subsets,"rank.call"))
fmList<-get.models(best.subsets,1:2)
summary(model.avg(fmList))
```




----------------------------------------------------------------------------------------------------------------------

What happens if we don't use random effects, but specify all terms as fixed?

### Model simplification by likelihood ratio test ###

Retain site, year and species as designed components of experiment. Test significance of environmental predictors by stepwise deletion.

```{r mlm}
mlm1 <- lm(acorn_count ~ species + site_name + year + mean_max_April_temp + mean_max_March_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + mean_max_summer_temp, data=statsdata)
summary(mlm1)

# Model checking
plot(mlm1) # no large deviations from LM assumptions
summary(mlm1)
aov(mlm1)

mlm2 <- update(mlm1, . ~ . - mean_max_summer_temp)
anova(mlm2, mlm1) # No significant difference, drop term
summary(mlm2)

mlm3 <- update(mlm2, . ~ . - April_rain)
anova(mlm3, mlm2) # No significant difference, drop term. Correlated with March_rain so this term may be significant in March_rain is removed from model
summary(mlm3)

mlm4 <- update(mlm3, . ~ . - March_rain_lagged1)
anova(mlm4, mlm3) # Significant
summary(mlm4)

mlm5 <- update(mlm3, . ~ . - mean_max_March_temp)
anova(mlm5, mlm3) # Significant

mlm6 <- update(mlm3, . ~ . - March_rain)
anova(mlm6, mlm3) # Significant

mlm7 <- update(mlm4, . ~ . - April_rain_lagged1)
anova(mlm7, mlm3) # Significant

mlm8 <- update(mlm4, . ~ . - mean_max_April_temp)
anova(mlm8, mlm3) # Significant
```

Significant terms retained after step-wise model simplification by log-likelihood at alpha=0.05:

* March_rain_lagged1
* mean_max_March_temp
* March_rain
* April_rain_lagged1
* mean_max_April_temp


### Model simplification by AIC ###

Repeat analysis using stepAIC

```{r dropterm}
mlmAIC <- stepAIC(mlm1, scope = list(lower = ~ site_name + species + year))
summary(mlmAIC)
```

Retains same terms as stepwise model simplification!

### Summary of survery responses ###

Load file that summarizes survery responses. For each of the seven environmental predictors, gives the percent of final models that included that predictor. Plot.

```{r summary}
rs <- read.table("response_summary.tsv", header=T, sep="\t")
colnames(rs)[2] <- "Model_type"
ggplot(rs, aes(x=factor(Model_type), y=percent_included, fill=Model_type)) + geom_bar(stat="identity") + facet_grid(. ~ term) + labs(x="Term", y="% of models including term")

# Repeat after dropping 'other'
rs1 <- rs[rs$"Model_type"!="other",]
p <- ggplot(rs1, aes(x=factor(Model_type), y=percent_included, fill=factor(Model_type))) + geom_bar(stat="identity") + facet_grid(. ~ term) + labs(x="Term", y="% of models including term")
p + scale_fill_grey()
```


Prediction and plotting to compare multiple methods
cross-validation method where one year is dropped and predict for that year

```{r prediction}
# Trial data
trial_statsdata <- subset(statsdata, year != 2011, )
trial_statsdata <- droplevels(trial_statsdata)
str(trial_statsdata)
unique(trial_statsdata$year) # 2011 dropped successfully
# Test data
test_statsdata <- subset(statsdata, year == 2011, )
test_statsdata <- droplevels(test_statsdata)
str(test_statsdata)
unique(test_statsdata$year) # 2011 dropped successfully

# Fit mlm
s_mlm1 <- lm(acorn_count ~ site_name + year + mean_max_April_temp + mean_max_March_temp + March_rain + April_rain_lagged1, data = trial_statsdata)
summary(s_mlm1)
p.mlm1 <- predict(s_mlm1, newdata = test_statsdata, se.fit=TRUE)

# Fit lmer model 
s_lmer1 <- lmer(acorn_count ~ April_rain + March_rain_lagged1 + April_rain_lagged1 + (1|site_name) + (1|year), data=trial_statsdata)
summary(s_lmer1)
p.lmer1 <- predict(s_lmer1, newdata = test_statsdata, se.fit=TRUE)

# Fit best model by AIC
s_AIC1 <- lmer(acorn_count ~ April_rain_lagged1 + (1|site_name) + (1|year), data=test_statsdata)
summary(s_AIC1)
p.AIC1 <- predict(s_AIC1, newdata = test_statsdata, se.fit=TRUE)

# New dataframe with predictions from different models
ptest <- test_statsdata[,1:4]
colnames(ptest)[4] <- c("resp")
ptest$se <- 0
ptest$type <- "true"
# Add predicted values and standard errors from first model
ptest <- rbind(ptest ,cbind(ptest[,1:3], type=rep("mlm",20), resp = p.mlm1$fit, se = p.mlm1$se.fit))
# ...second model
ptest <- rbind(ptest ,cbind(ptest[,1:3], type=rep("lmer",20), resp = p.lmer1$fit, se = p.lmer1$se.fit))
#...third model
ptest <- rbind(ptest ,cbind(ptest[,1:3], type=rep("AIC",20), resp = p.AIC1$fit, se = p.AIC1$se.fit))

# Errorbar plot showing truth and different predictions
limits <- aes(ymax=ptest$resp + ptest$se, ymin=ptest$resp - ptest$se)

dodge <- position_dodge(width=0.9)

p1 <- ggplot(ptest, aes(colour=type, y=resp, x=site_name)) + geom_point() + geom_errorbar(limits)
p1 

p2 <- ggplot(ptest, aes(x=factor(type), y=resp, fill=factor(site_name))) + geom_bar(stat="identity") + facet_grid(. ~ site_name) 
p2
# not what I want...odd the 'resp' has values up to 20 when it should not...

# partial regression plots
avPlots(s_mlm1)

s_mlm2 <- lm(acorn_count ~ year + mean_max_April_temp + mean_max_March_temp + March_rain + April_rain_lagged1, data = trial_statsdata)
avPlots(s_mlm2)
```



```{r session}
sessionInfo()
```