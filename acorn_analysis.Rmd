Example analysis of "stats_data.csv" for survey of statistical methods
========================================================

**Author:** [John Stanton-Geddes](www.johnstantongeddes.org), <john.stantongeddes.research@gmail.com>

**Created:** 2013-05-13

Data is a subset of data file from the paper "Walter D. Koenig and Johannes M. H. Knops. 2013. Large-scale spatial synchrony and cross-synchrony in statsdata production by two California oaks. Ecology. 94:83â€“93. http://dx.doi.org/10.1890/12-0940.1" downloaded from [Ecological Archives](http://esapubs.org/archive/ecol/E094/009/). Seven of the original 13 environmental variables were selected based on an analysis of the full data set to reduce complexity of model fitting for participants. Some of the columns were renamed for convenience of analysis in R.

Response is acorn_count (per 30 seconds of counting, log transformed) collected from multiple sites over multiple years with many potential predictors. 

We in no way intend this as a criticism or an endorsement of the analysis performed by Koenig and Knops. We quite liked their paper, but simply selected this data set as it was freely available from *Ecological Archives* and fit our requirements of a single response and a number of potentially-important and associated predictors.

----------------------------------------------------------

Load and examine data

```{r}
library(MASS)
library(nlme)
library(lme4)
library(MuMIn)
library(ggplot2)
library(SciViews)
library(knitr)
```

Load data

```{r data}
statsdata <- read.csv("stats_data.csv", header=TRUE, sep=",")
head(statsdata)
str(statsdata)
```

Check distribution of acorn_count

```{r statsdatadist}
hist(statsdata$acorn_count) # Mode at 0 and flat to 3 
```


Load data file with terms included in final models provided by survey participants

```{r variables data}
selections.raw<-read.csv("selected_variables.csv", na.strings="NA")
head(selections.raw)

# Remove models not selectd by AIC or P-value
variables<-selections.raw[!(is.na(selections.raw$Method)), -c(1:4)]
dim(variables)
head(variables)
colSums(variables, na.rm=T)
rowSums(variables, na.rm=T)

# Create matrix 8x8 matrix and fill lower triangle. First column is the number of times each variable is included in a final model. Off-diagonals are the number of times each pair-wise combination of variables are included in final model.
var.mat <- matrix(NA, nrow=8, ncol=8)

# First column
var.mat[2:8,1] <- colSums(variables, na.rm=T)[2:8]

# For each pair of environmental predictors, report number of times combination is used in a final model
jstart <- 4

for(j in jstart:9) {
  cat(jstart, '\n')
  varj <- colnames(variables)[j]
  cat(varj, '\n')
  for (i in (jstart+1):10) {
    vari <- colnames(variables)[i]
    cat(vari, '\n')
    #print(length(which(variables[,vari]==1 & variables[,varj]==1)))
    var.mat[i-2,j-2] <- length(which(variables[,vari]==1 & variables[,varj]==1))
  }
  jstart <- jstart+1
}

var.mat
```


## Graphical exploration ##

```{r explore}
# Load customized pairs function that allows plotting specific values in lower triangle
source("pairs-JSG.R")

# Create pairs with histograms on diagonal
# make empty vector "labels" to prevent labels from being printed
labels = c("Acorn \n count", "Max April \n Temp", "Max March \n Temp", "March rain", "April rain", "Lagged \n March rain", "Lagged \n April rain", "Max summer \n Temp")

# custom pairs plot
postscript("Fig1-pairs.eps")
suppressWarnings(pairsJSG(statsdata[,4:11], lower.panel=panel.sp, upper.panel=panel.smooth, diag.panel=panel.density, labels=labels, m=var.mat, col.smooth="black"))
dev.off()
```

    
## Model selection by step-wise deletion ##

Fit mixed-effects model with site and year as random effects and all environmental predictors as fixed. 

```{r lmer}
lmer1 <- lmer(acorn_count ~ mean_max_April_temp + mean_max_March_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + mean_max_summer_temp + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer1)
anova(lmer1)

lmer2 <- lmer(acorn_count ~ mean_max_April_temp + mean_max_March_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer2)
anova(lmer2, lmer1)
# Drop mean_max_summer_temp
anova(lmer2)

lmer3 <- lmer(acorn_count ~ mean_max_April_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer3)
anova(lmer3, lmer2)
# Drop mean_max_March_temp
anova(lmer3)

lmer4 <- lmer(acorn_count ~ mean_max_April_temp + April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer4)
anova(lmer4, lmer3)
# Drop March_rain
anova(lmer4)

lmer5 <- lmer(acorn_count ~ April_rain + March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer5)
anova(lmer5, lmer4)
# Drop mean_max_April_temp
anova(lmer5)

lmer6 <- lmer(acorn_count ~ March_rain_lagged1 + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer6)
anova(lmer6, lmer5)
# Retain April_rain

lmer7 <- lmer(acorn_count ~ April_rain + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer7)
anova(lmer7, lmer5)
# Marginally retain March_rain_lagged1 at alpha=0.05, but not after multiple testing

lmer8 <- lmer(acorn_count ~ April_rain + April_rain_lagged1 + species + (1|site_name) + (1|year), data=statsdata)
summary(lmer8)
anova(lmer8, lmer5)
# Marginally retain April_rain_lagged1 at alpha=0.05, but not after multiple testing

# Check correlations among these variables
pairs(statsdata[,c(4,8:10)])
```

Final model retains April_rain. March_rain_lagged1 and April_rain_lagged1 are marginally significant at alpha=0.05 but would not be retained if correcting for multiple testing.


## Model selection by AIC ##

Use dredge function in the [MuMIn](http://cran.r-project.org/web/packages/MuMIn/MuMIn.pdf) package that performs automated model selection testing all possible combinations of models. Model averaging of the 'best' models. 


```{r dredge}
best.subsets<-dredge(lmer1,rank="AIC",trace=TRUE,fixed=~n)

print(best.subsets,abbrev.names=FALSE)

#Dredge reports two best fit models. Average them with MuMIn.

(attr(best.subsets,"rank.call"))
fmList<-get.models(best.subsets,1:2)
summary(model.avg(fmList))
```




----------------------------------------------------------------------------------------------------

What happens if we don't use random effects, but specify all terms as fixed?

### Model simplification by likelihood ratio test ###

Retain site, year and species as designed components of experiment. Test significance of environmental predictors by stepwise deletion.

```{r mlm}
mlm1 <- lm(acorn_count ~ species + site_name + year + mean_max_April_temp + mean_max_March_temp + March_rain + April_rain + March_rain_lagged1 + April_rain_lagged1 + mean_max_summer_temp, data=statsdata)
summary(mlm1)

# Model checking
plot(mlm1) # no large deviations from LM assumptions
summary(mlm1)
aov(mlm1)

mlm2 <- update(mlm1, . ~ . - mean_max_summer_temp)
anova(mlm2, mlm1) # No significant difference, drop term
summary(mlm2)

mlm3 <- update(mlm2, . ~ . - April_rain)
anova(mlm3, mlm2) # No significant difference, drop term. Correlated with March_rain so this term may be significant in March_rain is removed from model
summary(mlm3)

mlm4 <- update(mlm3, . ~ . - March_rain_lagged1)
anova(mlm4, mlm3) # Significant
summary(mlm4)

mlm5 <- update(mlm3, . ~ . - mean_max_March_temp)
anova(mlm5, mlm3) # Significant

mlm6 <- update(mlm3, . ~ . - March_rain)
anova(mlm6, mlm3) # Significant

mlm7 <- update(mlm4, . ~ . - April_rain_lagged1)
anova(mlm7, mlm3) # Significant

mlm8 <- update(mlm4, . ~ . - mean_max_April_temp)
anova(mlm8, mlm3) # Significant
```

Significant terms retained after step-wise model simplification by log-likelihood at alpha=0.05:

* March_rain_lagged1
* mean_max_March_temp
* March_rain
* April_rain_lagged1
* mean_max_April_temp


### Model simplification by AIC ###

Repeat analysis using stepAIC

```{r dropterm}
mlmAIC <- stepAIC(mlm1, scope = list(lower = ~ site_name + species + year))
summary(mlmAIC)
```

Retains same terms as stepwise model simplification!



## Time series model ##

Average across site and species and predict for each year

```{r timeseries}
# Create time series plot of statsdata count averaged across site and species
statsdata.ts <- with(statsdata, aggregate(acorn_count ~ year, FUN=mean))
statsdata.ts <- ts(statsdata.ts$acorn_count, start=1994, end=2011)

# Create dataframe with yearly average statsdata count 
dat <- subset(statsdata, select=c(year, acorn_count:mean_max_summer_temp))
dat <- stats::aggregate(cbind(acorn_count, mean_max_April_temp, mean_max_March_temp, 
March_rain, April_rain, March_rain_lagged1, April_rain_lagged1, 
mean_max_summer_temp) ~ year, FUN=mean, data=dat)
dat <- dat[,-1]

## Fit OLS model
mod.ols <- lm(formula(dat), data=dat)
summary(mod.ols)

## Model selection by NHST
mod.ols2 <- update(mod.ols, ~. -April_rain)
anova(mod.ols2, mod.ols) 
# Not significant
summary(mod.ols2)
mod.ols3 <- update(mod.ols2, ~. -March_rain_lagged1)
anova(mod.ols3, mod.ols2) 
# Not significant
summary(mod.ols3)
mod.ols4 <- update(mod.ols3, ~. -mean_max_summer_temp)
anova(mod.ols4, mod.ols3) 
# Not significant
summary(mod.ols4)
mod.ols5 <- update(mod.ols4, ~. -mean_max_March_temp)
anova(mod.ols5, mod.ols4) 
# Significant - retain all remaining terms

## Model selection by AIC
mod.ols.AIC <- stepAIC(mod.ols)
summary(mod.ols.AIC)

# Fit minimal model
mod.ols.min <- update(mod.ols5, ~. - mean_max_April_temp - April_rain_lagged1)
summary(mod.ols.min)

## Plot time series and predictions
postscript("Fig2-time-series.eps")
plot(statsdata.ts, lwd=2, ylim=c(0, 3.5), xlab="Year", ylab="Acorn count", lty=1, las=1)
lines(x=1994:2011, y=predict(mod.ols), col="black", lty=2, lwd=2)
lines(x=1994:2011, y=predict(mod.ols4), col="black", lty=3)
lines(x=1994:2011, y=predict(mod.ols.AIC), col="black", lty=4, lwd=2)
lines(x=1994:2011, y=predict(mod.ols.min), col="black", lty=5, lwd=2)
dev.off()
```

Check if linear model (not time series) as above has similar results to time series

```{r lmer again}
lmer9 <- lmer(acorn_count ~ April_rain + March_rain_lagged1 + April_rain_lagged1 + (1|year), data=statsdata)
summary(lmer9)

lmer10 <- lmer(acorn_count ~ April_rain + April_rain_lagged1 + (1|year), data=statsdata)
anova(lmer10, lmer9)

lmer11 <- lmer(acorn_count ~ April_rain + March_rain_lagged1 + (1|year), data=statsdata)
anova(lmer11, lmer9)

lmer12 <- lmer(acorn_count ~ April_rain + (1|year), data=statsdata)
anova(lmer12, lmer11)

lmer13 <- lmer(acorn_count ~ March_rain_lagged1 + (1|year), data=statsdata)
anova(lmer13, lmer11)
```

Interesting -- results are not the same as time series analysis. April rain is significant, consistent with LMER including site and secies and TS models, but April_rain_lagged1 is also signifcant, though only marginally so in LMER+site+species. March_rain_lagged1 is marginally significant which is consistent with previous lmer. 

To examine differences in predictive ability among the final models from survey participants, perform a simulation. Load table with the method and terms included in each of the final models. Divide data into trial (70% of observations) and test (30% of observations) data. Fit linear models (not exactly what each participant did, but a first approximation) on trial data, and predict on test data. Calculate squared error for each model as the deviation of the predicted alues from the observed values in the test dataset.

```{r final models}
# From final models by participants (selected_variables.csv), remove models not selectd by AIC or P-value and those that did not retain any terms
selections<-selections.raw[!(is.na(selections.raw$Method)|(rowSums(selections.raw[,-c(1:4)],na.rm=T)==0)),-c(1:4)]
head(selections)

# Number of parameters included in each final model
rowSums(selections,na.rm = T)
```

```{r bootstrap models}
Nruns=400
validationS <- 30 # percentage of data to validation

# Fit Nruns models for each final model and calculate error
SSsd <- SSmean <- {}
for (i in 1:nrow(selections)){
    SS <- {}
    for (j in 1:Nruns){ 
        remove30 <- sample(nrow(statsdata),floor(validationS*nrow(statsdata)/100))
        data2model <- statsdata[-remove30,c(colnames(selections)[!is.na(selections[i,])],"acorn_count")]
        data2predict <- statsdata[remove30,c(colnames(selections)[!is.na(selections[i,])],"acorn_count")]
        lm1 <- lm(acorn_count~.,data=data2model)
        predicted <- predict(lm1,newdata = data2predict,type="response")
        error <- data.frame(data2predict,predicted,diff=predicted-data2predict$acorn_count,Squares=(predicted-data2predict$acorn_count)^2)
        SS[j] <- sum(error$Squares)
    }
    SSmean [i] <- mean(SS)
    SSsd [i] <- sd(SS)
}


# Randomly select parameters, from 1 to 10, for predictive ability without model selectin
SSsdT <- SSmeanT <- {}

for (i in 1:10){
    SST <- {}
    for (j in 1:Nruns){
     
       
        remove30 <- sample(nrow(statsdata),floor(validationS*nrow(statsdata)/100))
        form<-as.formula(paste("acorn_count","~",paste(sample(colnames(statsdata)[colnames(statsdata)!="acorn_count"],i),collapse = "+")))
        data2model <- statsdata[-remove30,]
        data2predict <- statsdata[remove30,]
        lm1 <- lm(form,data=data2model)
        predicted <- predict(lm1,newdata = data2predict,type="response")
        error <- data.frame(data2predict,predicted,diff=predicted-data2predict$acorn_count,Squares=(predicted-data2predict$acorn_count)^2)
        SST[j] <- sum(error$Squares)
    }
    SSmeanT [i] <- mean(SST)
    SSsdT [i] <- sd(SST)
}

## Plot!
postscript("Fig3-squared-error-vs-parameters.eps")

plot(SSmean~rowSums(selections,na.rm = T),pch=21,bg=selections.raw[rownames(selections),]$Method,xlab = "Number of parameters", ylab = "Squared deviation from expected",cex=1.5,cex.lab=1,xlim=c(1,10),ylim = c(60,170),type="n", las=1)

polygon(data.frame(x=c(1:10,10:1),y=c(SSmeanT-1.96*SSsdT,rev(SSmeanT+1.96*SSsdT))),col="gray",border=NA)
points(spline(1:10,SSmeanT),pch=21,bg=3,cex=1.5,cex.lab=2,type="l")

arrows(rowSums(selections,na.rm = T),SSmean-1.96*SSsd,rowSums(selections,na.rm = T),SSmean+1.96*SSsd,angle = 90,length=0.05,code = 3)
points(SSmean~rowSums(selections,na.rm = T),pch=as.integer(selections.raw[rownames(selections),]$Method)*2+18,xlab = "Number of parameters", ylab = "Squared deviation from expected",cex=1.5,cex.lab=1,xlim=c(1,10),ylim = c(20,150))

dev.off()
```



```{r session}
sessionInfo()

# save as R script without markdown
purl("acorn_analysis.Rmd")
```
